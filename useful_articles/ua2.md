# 训练神经网络的秘诀

原文地址：[A Recipe for Training Neural Networks (karpathy.github.io)](https://karpathy.github.io/2019/04/25/recipe/)

几周前，我发布了一条关于 "最常见的神经网络错误" 的推文，列举了一些与神经网络训练相关的常见问题。这条推文获得了比我预期更多的参与(包括一场网络研讨会:))。显然，很多人都亲身经历过 "卷积层是这样工作的" 与 "我们的卷积网络取得了最先进的结果" 之间的巨大差距。

因此，我想把我尘封已久的博客刷屏，把我的推文扩展成这个话题应有的长篇形式，会很有趣。不过，我并不想枚举更常见的错误或对它们进行详细说明，而是想更深入地挖掘一下，谈谈如何才能完全避免犯这些错误（或快速纠正它们）。这样做的诀窍在于遵循一定的流程，而就我所知，这种流程并不经常被记录下来。让我们先来看看促使我们这样做的两个重要原因。

### 1) 神经网络训练是一个漏洞百出的抽象概念

据称，训练神经网络很容易上手。许多库和框架都以展示 30 行奇迹代码片段来解决数据问题为荣，给人一种即插即用的（错误）印象。我们经常能看到这样的例子

```pyhton
>>> your_data = # plug your awesome dataset here
>>> model = SuperCrossValidator(SuperDuper.fit, your_data, ResNet50, SGDOptimizer)
# conquer world here
```

这些库和示例激活了我们大脑中熟悉标准软件的部分--在这里，简洁的 API 和抽象通常是可以实现的。请求库演示：

```python
>>> r = requests.get('https://api.github.com/user', auth=('user', 'pass'))
>>> r.status_code
200
```

太酷了！一位勇敢的开发者为你分担了理解查询字符串、urls、GET/POST 请求、HTTP 连接等的重担，并在很大程度上将复杂性隐藏在了几行代码之后。这就是我们所熟悉和期待的。不幸的是，神经网络并非如此。它们不是 "现成" 的技术，只要你稍微偏离 ImageNet 分类器的训练。我曾在 "[是的，你应该了解反向传播](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)" 一文中试图说明这一点，挑出反向传播的毛病，称其为 "漏洞百出的抽象"，但不幸的是，情况要严重得多。反向传播 + SGD 并不能神奇地让你的网络正常工作。Batch Norm 并不能神奇地让你的网络收敛得更快。RNN 不会神奇地让你 "插入" 文本。你可以将问题表述为 RL 并不意味着你应该这样做。如果你坚持使用这种技术，却不了解它是如何工作的，那么你很可能会失败。这让我想到......

### 2) 神经网络训练悄无声息地失败

当你破坏或错误配置代码时，往往会出现某种异常。你输入了一个整数，而预期的是一个字符串。函数预计只有 3 个参数。导入失败。该键不存在。两个列表中的元素数量不相等。此外，通常还可以为某个功能创建单元测试。

在训练神经网络时，这只是一个开始。从语法上讲，一切都可能是正确的，但整体上并没有安排妥当，这就真的很难说了。"可能的错误面" 很大，而且是逻辑性的(而不是语法性的)，单元测试起来非常棘手。例如，在数据增强过程中左右翻转图像时，你可能忘了翻转真实标签。你的网络仍然可以（令人震惊地）运行得很好，因为你的网络可以在内部学习检测翻转图像，然后左右翻转其预测结果。又或者，你的自回归模型由于一个 "偏一" 错误，意外地将它试图预测的东西作为了输入。或者你试图梯度剪裁，但却剪裁了损失，导致离群实例在训练过程中被忽略。或者你从预训练的检查点初始化了权重，但没有使用原始平均值。或者，你只是搞砸了正则化强度、学习率、它的衰减率、模型大小等设置。因此，只有在幸运的情况下，你配置错误的神经网络才会出现异常；大多数情况下，神经网络会进行训练，但会默默地工作得更差一些😕 。

因此，（这一点无论如何强调都不为过）**"急功近利" 的神经网络训练方法是行不通的**，只会带来痛苦。现在，痛苦是让神经网络良好工作的一个非常自然的部分，但它可以通过彻底、防御、偏执和痴迷于对所有可能的事情进行可视化来减轻。根据我的经验，**与深度学习成功最密切相关的品质是耐心和对细节的关注**。🚀️

### 秘诀

鉴于以上两个事实，我为自己制定了一套具体的流程，在应用神经网络解决新问题时，我将尝试对其进行描述。你会发现，它非常重视上述两个原则。特别是，它从简单到复杂，每一步我们都要对将要发生的事情做出具体的假设，然后通过实验来验证，或者进行调查，直到发现问题为止。我们**极力避免的是一次性引入大量 "未经验证" 的复杂性**，因为这势必会引入错误/配置不当，而这些错误/配置不当永远都找不到（如果能找到的话）。如果编写神经网络代码就像训练神经网络一样，你就会希望使用很小的学习率和猜测，然后在每次迭代后评估完整的测试集。

#### 1. 与数据融为一体

训练神经网络的第一步是**完全不接触任何神经网络代码，而是从彻底检查数据开始**。这一步至关重要。我喜欢**花大量时间（以小时为单位）扫描成千上万的示例，了解它们的分布并寻找规律**。幸运的是，你的大脑在这方面非常擅长。有一次，我发现数据中包含重复的示例。还有一次，我发现了损坏的图像/真实标签。我**寻找数据的不平衡和偏差**。我通常还会关注自己**对数据进行分类**的过程，这也暗示了我们最终要探索的架构类型。举例来说--局部特征是否足够，还是需要全局上下文？变异的程度和形式如何？哪些变化是虚假的，可以预处理掉？空间位置是否重要？细节有多重要，我们可以在多大程度上降低图像的采样率？真实标签的噪声有多大？

此外，由于神经网络实际上是数据集的压缩/编译版本，因此你可以查看你的网络（错误）预测，并了解它们的来源。如果你的网络给出的预测与你在数据中看到的不一致，那就说明有问题。

一旦有了定性的认识，最好还能编写一些简单的代码，按照你能想到的任何方式（如标签类型、注释大小、注释数量等）进行搜索/过滤/排序，并可视化它们的分布以及任何坐标轴上的异常值。尤其是离群值，几乎总能发现数据质量或预处理中的一些错误。

#### 2. 建立端到端训练/评估框架 + 获取简单的基线

既然我们已经了解了我们的数据，那么我们是否可以使用我们的超炫多尺度 ASPP FPN ResNet 开始训练超棒的模型呢？当然不能。这是一条痛苦之路。我们的下一步是建立一个完整的训练+评估框架，并通过一系列实验获得对其正确性的信任。在这一阶段，最好选择一些简单的模型，你不可能莫名其妙地搞砸了--例如线性分类器，或者一个非常小的 ConvNet。我们需要对其进行训练、可视化损失、任何其他指标（如准确率）、模型预测，并在此过程中进行一系列带有明确假设的消融实验。

##### 本阶段的提示和技巧：

**固定随机种子**。一定要使用固定的随机种子，以保证运行两次代码时得到相同的结果。这样可以消除变异因素，让你保持清醒。

**简化**。确保禁用任何不必要的装饰。例如，在此阶段一定要关闭任何数据增强功能。数据增强是一种正则化策略，我们可能会在以后采用，但现在它只是引入一些愚蠢错误的另一个机会。

**在评估中添加有效数字**。在绘制测试损失图时，要对整个（大）测试集进行评估。不要只绘制这个 batch 的测试损失图，然后在 Tensorboard 中对其进行平滑处理。我们在追求正确性的同时，也非常愿意为保持理智而放弃时间。

**验证损失 @init**。验证损失从正确的损失值开始。例如，如果你正确地初始化了最终层，那么在初始化时就应该测量 softmax 上的 `-log(1/n_classes)`。同样的默认值也可以用于 L2 回归、Huber 损失等。

**正确初始化**。正确初始化最终层权重。例如，如果你要回归一些均值为 50 的值，那么就将最终偏置初始化为 50。如果你的数据集不平衡，正负比为 1:10，那么在初始化时设置对数偏置，使网络预测概率为 0.1。正确设置这些偏置会加快收敛速度，并消除 "曲棍球" 损失曲线，**因为在最初几次迭代中，网络基本上只是在学习偏置**。

**人类性能基线**。监控除损失以外的其他可由人工解释和检查的指标（如准确率）。尽可能评估自己（人类）的准确性并与之比较。或者，对测试数据进行两次标注，并将每个示例的一次标注视为预测，第二次标注视为准确标记。
输入无关基线。

**训练一个与输入无关的基线**（例如，最简单的方法是将所有输入设为 0）。这样做的结果应该会比不清 0 直接输入数据的结果更差。也就是说，你的模型是否学会了从输入中提取任何信息？

**过拟合一批数据**。过拟合一批仅有的几个示例（如两个示例）。为此，我们要增加模型的容量（如增加层或过滤器），并验证我们是否能达到可实现的最低损失（如 0）。我还喜欢在同一张图中直观地显示真实标签和预测结果，并确保一旦达到最小损失，它们最终会完全一致。如果它们不一致，就说明某个地方出了问题，我们就无法继续下一阶段的工作。

**验证训练损失的递减**。在这一阶段，由于你使用的是一个玩具模型，所以希望你的数据集欠拟合。试着增加一点它的容量。训练损失是否如期减少？

**在网络之前进行可视化**👀️。 将数据可视化👀️的正确位置是在 `y_hat = model(x)`（或 tf 中的 `sess.run`）之前。也就是说，你要对进入网络的数据进行可视化，将原始数据张量和真实标签解码为可视化数据。这是唯一的 "真理之源"。**在数据预处理和增强过程中，我数不清有多少次因此而获救，也数不清有多少次因此而发现问题**。

**预测动态可视化**。我喜欢在训练过程中对固定测试批次的模型预测进行可视化。这些预测的 "动态" 变化会让你对训练的进展有难以置信的直观感受。很多时候，如果网络在某些方面抖动过大，就有可能感觉到它在 "努力" 适应数据，从而暴露出不稳定性。极低或极高的学习率也很容易从抖动量上看出来。

**使用 backprop 来绘制依赖关系图**。你的深度学习代码通常会包含复杂、矢量化和广播式操作。我遇到过几次比较常见的错误，那就是人们弄错了（例如，他们在某处使用 `view` 而不是 `transpose`/`permute`），无意中将信息混入了批处理维度。一个令人沮丧的事实是，你的网络通常在训练时仍能正常运行，因为它会学会忽略来自其他示例的数据。调试这种情况（以及其他相关问题）的一种方法是，将损失设置为实例 **i** 的所有输出之和等微不足道的值，然后一路运行反向传播到输入，并确保只在 **第 i 个** 输入上获得非 0 梯度。同样的策略也可以用来确保自回归模型在时间 t 只取决于 1...t-1 等。更广泛地说，梯度可以提供给你的信息取决于你的网络中的信息，这对调试非常有用。

**泛化特例**。这是一个比较通用的编码技巧，但我经常看到有人从头开始编写一个相对通用的功能，当他们咬下太多以至于无法咀嚼时就会产生错误。我喜欢针对我现在正在做的事情编写一个非常具体的函数，让它发挥作用，然后再将其泛化，确保得到相同的结果。这通常适用于矢量化代码，我几乎总是先写出完全循环的版本，然后才一个循环一个循环地将其转化为矢量化代码。

#### 3. 过拟合

在这一阶段，我们应该已经对数据集有了很好的了解，而且我们已经有了完整的训练和评估流程。对于任何给定的模型，我们都可以（可重复地）计算出一个值得信赖的指标。我们还掌握了与输入无关的基线的性能、一些简单基线的性能（我们最好能打败它们），以及人类的大致性能（我们希望能达到这个水平）。现在，我们已经具备了迭代一个好模型的条件。

我喜欢的寻找好模型的方法分为两个阶段：首先得到一个足够大的模型，使其能够过拟合（即关注训练损失），然后对其进行适当的正则化（放弃一些训练损失以改善验证损失）。我喜欢这两个阶段的原因是，如果我们根本无法通过任何模型达到较低的误差率，这可能再次表明存在一些问题、错误或配置不当。

##### 本阶段的一些提示和技巧：

**挑选模型**。为了获得良好的训练损失，你需要为数据选择一个合适的架构。说到选择，我的第一条建议是：**不要逞英雄**😕。我见过很多人热衷于疯狂地、创造性地将神经网络工具箱中的**乐高积木**😄 堆砌成各种奇特的架构，这对他们来说很有意义。**在项目的早期阶段，要坚决抵制这种诱惑**。`<font color=red>`我总是建议人们简单地找到最相关的论文，然后复制粘贴他们能实现良好性能的最简单架构`</font>`👍 。例如，如果你正在对图像进行分类，不要逞英雄，直接复制粘贴一个 ResNet-50 作为第一次运行。你可以在以后做一些更个性化的事情，并超越它。

**亚当是安全的**。在设定基线的早期阶段，我喜欢使用学习率为 3e-4 的 Adam。根据我的经验，Adam 对超参数（包括不良学习率）的宽容度更高。对于 ConvNets，经过良好调整的 SGD 几乎总能略微优于 Adam，但最佳学习率区域要狭窄得多，而且要针对具体问题。(注：如果你使用的是 RNN 和相关序列模型，则使用 Adam 更为常见。在项目的初始阶段，还是那句话，不要逞强，相关论文做什么，你就跟着做什么）。

**一次只将一个信号复杂化**。如果你有多个信号要接入分类器，我建议你逐个接入，每次都要确保获得预期的性能提升。不要一开始就把厨房水槽扔到模型上😕 。还有其他提高复杂度的方法，例如，你可以尝试先插入较小的图像，然后再把它们变大，等等。

**不要相信学习率衰减默认值**。如果你要重新使用其他领域的代码，请务必谨慎对待学习率衰减。你不仅要针对不同的问题使用不同的衰减时间表，更糟糕的是，在典型的实现中，时间表将基于当前训练周期数，而这可能仅仅取决于数据集的大小，变化很大。例如，ImageNet 将在训练周期 30 时衰减 10。如果你不是在训练 ImageNet，那么你几乎肯定不希望这样。一不小心，你的代码就会过早地将学习率降至零，导致模型无法收敛。**在我自己的工作中，我总是完全禁用学习率衰减（我使用恒定的 LR），并在最后调整学习率**。

#### 4. 正则化

理想情况下，我们现在已经有了一个大型模型，它至少可以拟合训练集。现在是对其进行正则化的时候了，通过放弃一些训练精度来获得一些验证精度。

##### 一些技巧和窍门：

**获取更多数据**。首先，在任何实际情况下，对模型进行正则化的最佳和首选方法就是**添加更多真实的训练数据**。在可以收集更多数据的情况下，花费大量工程周期试图从一个小数据集中榨取![](./juice.png)是一个非常常见的错误。据我所知，增加更多数据几乎是唯一能保证配置良好的神经网络性能无限单调提升的方法。另一种方法是(模型)组合（如果你负担得起的话），但这种方法在大约 5 个模型后就会失效。

**数据增强**。仅次于真实数据的是半假数据——尝试更激进的数据增强。

**创造性增强**。如果半假数据无法做到这一点，那么**假数据**也能做到。人们正在寻找创造性的方法来扩展数据集；例如，域随机化、使用模拟、巧妙的混合，例如在（可能是模拟的）场景中插入数据，甚至是 GAN。

**预训练**。即使有足够的数据，如果可以的话，**使用预训练网络**🎉️ 也无伤大雅。

**坚持监督学习**。不要对无监督预训练过于兴奋。与 2008 年的那篇博文所言不同，据我所知，在现代计算机视觉领域，没有任何版本的无监督预训练取得了很好的效果（不过，最近 BERT 和朋友们的 NLP 似乎做得很好，这很可能是由于文本更具深思熟虑的性质，以及更高的信噪比）。

**更小的输入维度**。去除可能包含虚假信号的特征。如果你的数据集较小，任何增加的虚假输入都是过拟合的另一个机会。同样，如果低层次细节并不重要，也可以尝试输入更小的图像。

**缩小模型尺寸**。在很多情况下，你可以利用领域知识对网络的约束来缩小其规模。举例来说，在 ImageNet 的主干顶层使用全连接层曾经是一种潮流，但后来这些层被简单的平均池化所取代，在此过程中省去了大量参数。

**减少 batch size**。由于批量归一化内部的归一化操作,较小的批量大小在某种程度上相当于更强的正则化效果。这是因为 batch 经验 mean/std 是完整 mean/std 的近似版本，因此缩放和偏移会使 batch "抖动" 得更厉害。

**丢弃**。添加 dropout。在 ConvNets 中使用 dropout2d（空间 dropout）。请谨慎使用，因为 dropout 似乎与批量归一化(一起工作)效果不佳。

**权重衰减**。增加权重衰减惩罚。

**提前停止**。根据测得的验证损失停止训练，以便在模型即将过拟合时抓住它。

**尝试更大的模型**。我最后才提到这一点，而且是在提前停止训练后才提到的，但我在过去曾多次发现，较大的模型当然最终会出现更多的过拟合，但其 "提前停止训练" 的性能往往比较小的模型要好得多。

最后，为了进一步确信你的网络是一个合理的分类器，**我喜欢将网络的第一层权重可视化，并确保获得合理的漂亮边缘**。如果你的第一层过滤器看起来像噪音，那么就可能有问题。同样，网络内部的激活有时也会显示出奇怪的假象，暗示存在问题。

#### 5. 调整

现在，你应该与你的数据集一起 "循环"，探索一个广阔的模型空间，寻找能够实现低验证损失的架构。

##### 在这一步中，有一些提示和技巧：

**随机网格搜索**。在同时调整多个超参数时，使用网格搜索以确保覆盖所有设置，听起来很诱人，但请记住，最好使用随机搜索。直观地说，这是因为神经网络通常对某些参数比其他参数更加敏感。在极限情况下，如果参数 **a** 很重要，但改变 **b** 却没有影响，那么你宁愿对参数 **a** 进行更全面的采样，而不是在几个固定点进行多次采样。

**超参数优化**。现在有很多花哨的贝叶斯超参数优化工具箱，我的一些朋友也报告说用它们取得了成功，但我个人的经验是，探索模型和超参数的美好而广阔空间的最先进方法是使用实习生😄 。开个玩笑。

#### 6. 榨出![](./juice.png)

一旦你找到最佳架构和超参数类型后，你还可以使用一些技巧来榨出系统中最后的果汁：

**模型组合**。模型组合是在任何情况下都能保证获得 2% 精度的方法。如果你无法承担测试时的计算量，可以利用[隐性知识](https://arxiv.org/pdf/1503.02531)将组合模型提炼成一个网络。

**离开，让它继续训练**。我经常看到有人在验证损失似乎趋于平稳时就停止模型训练。根据我的经验，网络的训练时间会非常长。有一次，我不小心在寒假期间离开了模型训练，当我一月份回来时，它已经是 SOTA（"最先进的"）了。

### 总结

一旦你来到这里，你就具备了成功的所有要素： 你已经对技术、数据集和问题有了深入的了解，你已经建立了整个训练/评估基础架构，并对其准确性有了很高的信心，你已经探索了越来越复杂的模型，并以你预测的方式获得了每一步的性能改进。现在，你已经准备好阅读大量论文、尝试大量实验并获得 SOTA 结果了。祝你好运！
