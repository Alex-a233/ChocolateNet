#### 读论文过程中想到的一些点子（有的行不通）

1. 可否学习染色法圈出息肉（2024.5.2）
2. 平坦型息肉的处理办法（2024.5.2）
3. 用 TGANet 取息肉准确标记的办法作监督（2024.5.14）
4. 应该让模型在训练阶段看到尽可能 **全** 的息肉类型
   将各种典型的 Polyp 抽取出来作为 trainset，让模型见到尽可能全的 Polyp。
   但是做论文还是先用原有的那一套数据集分布，因为这样方便对比原有的 SOTA 模型
   训练好之后，再换成 "Choosen trainset" 再进行训练 & 测试 & 评估各个 SOTA 也如是，这样可以证明这个训练设想的可行性和模型的学习能力（2024.6.11）
5. 为什么不用 Polyp-GEN 数据集，因为 Polyp-GEN 数据集给的图像多为医师行切除术时的图像，对模型推理的干扰很大，再者若医师已识别出息肉且已开始进行圈套切除，那么深度学习模型存在的意义是什么？
   个人认为深度学习模型的主要用处是辅助医师识别息肉，而不是在医师已经开始进行切除的时候再告诉医师哪里有息肉（2024.6.11）
6. 使用 hardNet-68 来做监督网络（2024.6.24）可能会效果不佳，因为 pvt-v2-b2 的性能由于 hardNet-68，但是深度学习的世界里事无绝对，所以不妨一试
7. 可以设计一种 "Boundary Attention" 来提升模型对息肉边界像素的关注以便更好地分割其边界，提升分割精度（2024.7.6）

---

1. 使用 SA+RA 构成 BoundaryAttention, 两个注意力分别处理 fm2, fm3, fm4, 然后分别处理 3 个特征图，最后通道维度叠加融合。（👎 ）
   再使用 SA+CA 构成 StructureAttention, 这个注意力仿照 Polyp-PVT 的写法。(2024.7.1)
   => 结果表明计算量过大, 16 个 G 的 GPU 直接 CUDA OUT OF MEMMORY（😕 ）
2. 改进一下，SA 和 RA 不再分别计算出通道数为 1 的特征图，先处理 RA 通道数不必归 1，先用 64，然后把处理后的特征图交给 SA 处理

---

1. Boundary Attention 对多个特征图应用减法，然后取反，取边界，边界内部统一改成 1（是否有些武断👀️ ），这样的话还要CA/SA吗？(2024.8.11)
2.